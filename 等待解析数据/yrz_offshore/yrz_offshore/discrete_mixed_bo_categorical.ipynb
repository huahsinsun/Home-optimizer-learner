{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "00018e33-90ca-4f63-b741-fe1fd43ca7db",
    "showInput": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bayesian Optimization over Discrete and Mixed Spaces via Probabilistic Reparameterization\n",
    "\n",
    "In this tutorial, we illustrate how to perform Bayesian Optimization (BO) over discrete and mixed spaces via probabilistic reparameterization.\n",
    "\n",
    "The key idea is that we can optimize an acquisition function $\\alpha(x, z)$ with discrete variables $z$ (and potentially continuous variables $ x$) by reparameterizing the discrete variables with random discrete varaibles $ Z$ that are parameterized by continuous parameters $\\theta$. This reparameterization enables optimizing the acquisition function by optimizing the following probabilistic objective:\n",
    "$$\\mathbb E_{Z \\sim P(Z|\\theta)}[\\alpha(x, Z)].$$\n",
    "\n",
    "The probabilistic objective is differentiable with respect to $\\theta$ (and $x$ so long as the acquisition function is differentiable with respect to $x$) and hence we can optimize the acquisition function with gradients.\n",
    "\n",
    "In this tutorial, we demonstrate how to use both an analytic version of probabilistic reparameterization (suitable when there are less than a few thousand discrete options) and a scalable Monte Carlo variant in BoTorch.\n",
    "\n",
    "S. Daulton, X. Wan, D. Eriksson, M. Balandat, M. A. Osborne, E. Bakshy. [Bayesian Optimization over Discrete and Mixed Spaces via Probabilistic Reparameterization](https://arxiv.org/abs/2210.10199), NeurIPS, 2022. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "customOutput": null,
    "executionStartTime": 1669843260741,
    "executionStopTime": 1669843260795,
    "originalKey": "029a9a6f-8db6-4d55-b122-d9ba064765ed",
    "requestMsgId": "f795e05e-6be2-4567-a6c6-8abe360c1e7f",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from botorch.models.transforms.factory import get_rounding_input_transform\n",
    "from botorch.test_functions.synthetic import SyntheticTestFunction\n",
    "from botorch.utils.sampling import draw_sobol_samples, manual_seed\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "tkwargs = {\"dtype\": dtype, \"device\": device}\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "4ba4e568-0ef2-430e-aecb-dae8889d6664",
    "showInput": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Problem setup\n",
    "\n",
    "Setup a categorical Ackley Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from botorch.models.transforms.input import OneHotToNumeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from botorch.test_functions.synthetic import Ackley\n",
    "dim = 5\n",
    "base_function = Ackley(dim=dim, negate=True).to(**tkwargs)\n",
    "# define categorical features\n",
    "feature_to_num_categories = {0: 3, 1: 4, 2: 4, 3: 3, 4: 3}\n",
    "start = None\n",
    "# creat a mapping from starting index in one-hot space to cardinality\n",
    "categorical_features = {}\n",
    "for idx, cardinality in sorted(feature_to_num_categories.items(), key=lambda kv: kv[0]):\n",
    "    if start is None:\n",
    "        start = idx\n",
    "    categorical_features[start] = cardinality\n",
    "    # add cardinality to start\n",
    "    start += cardinality\n",
    "# create a tensor of bounds of for the numeric representation of each categorical\n",
    "categorical_numeric_bounds = torch.zeros(2, dim, **tkwargs)\n",
    "# the upper bound is the cardinality - 1, respectively\n",
    "for idx, card in feature_to_num_categories.items():\n",
    "    categorical_numeric_bounds[1, idx] = card - 1\n",
    "one_hot_bounds = torch.zeros(2, sum(categorical_features.values()), **tkwargs)\n",
    "one_hot_bounds[1] = 1\n",
    "standard_bounds = one_hot_bounds\n",
    "one_hot_to_numeric_tf = OneHotToNumeric(dim=one_hot_bounds.shape[1], categorical_features=categorical_features).to(**tkwargs)\n",
    "one_hot_to_numeric_tf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1669843261778,
    "executionStopTime": 1669843261787,
    "originalKey": "223e42ea-10db-4510-b2b6-d51dbf114052",
    "requestMsgId": "6a161416-817d-48d7-bacb-816d02b8bfca",
    "showInput": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# construct a rounding function for initialization (equal probability for all discrete values)\n",
    "init_exact_rounding_func = get_rounding_input_transform(\n",
    "    one_hot_bounds=one_hot_bounds, categorical_features=categorical_features, initialization=True\n",
    ")\n",
    "# construct a rounding function\n",
    "exact_rounding_func = get_rounding_input_transform(\n",
    "    one_hot_bounds=one_hot_bounds, categorical_features=categorical_features, initialization=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1669843261804,
    "executionStopTime": 1669843261812,
    "originalKey": "d569119b-39d6-4de6-a5fc-83057239323f",
    "requestMsgId": "1c87ba69-f582-43e7-84f0-879c7672481d",
    "showInput": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def eval_problem(X):\n",
    "    # apply the exact rounding function to make sure\n",
    "    # that discrete parameters are discretized\n",
    "    X = exact_rounding_func(X)\n",
    "    # map to numeric\n",
    "    X_numeric = one_hot_to_numeric_tf(X)\n",
    "    # normalize from numeric space to unit cube\n",
    "    X_normalized = normalize(X_numeric, categorical_numeric_bounds)\n",
    "    # unnormalize from unit cube to the problem space\n",
    "    raw_X = unnormalize(X_normalized, base_function.bounds)\n",
    "    return base_function(raw_X).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1669843261842,
    "executionStopTime": 1669843261865,
    "originalKey": "b3c7d450-b82d-4e69-8c0c-667dc2ba6f17",
    "requestMsgId": "3f711388-d3d6-479f-aff4-85c456647121",
    "showInput": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_initial_data(n):\n",
    "    r\"\"\"\n",
    "    Generates the initial data for the experiments.\n",
    "    Args:\n",
    "        n: Number of training points..\n",
    "    Returns:\n",
    "        The train_X and train_Y. `n x d` and `n x 1`.\n",
    "    \"\"\"\n",
    "    raw_x = draw_sobol_samples(bounds=standard_bounds, n=n, q=1).squeeze(-2)\n",
    "    train_x = init_exact_rounding_func(raw_x)\n",
    "    train_obj = eval_problem(train_x)\n",
    "    return train_x, train_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "c262e98f-924d-414e-889f-7e65a37d3689",
    "showInput": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Model initialization\n",
    "\n",
    "We use a `FixedNoiseGP` to model the outcome. The models are initialized with 20 quasi-random points. We use an isotropic kernel over the binary parameters and an ARD kernel over the continuous parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "customOutput": null,
    "executionStartTime": 1669843261876,
    "executionStopTime": 1669843261884,
    "originalKey": "0d3cd746-3818-47c1-b16a-622c6035c264",
    "requestMsgId": "d499c927-365f-488c-82df-dafc04786744",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from botorch.models import FixedNoiseGP\n",
    "from botorch.models.kernels import CategoricalKernel\n",
    "from gpytorch.constraints import GreaterThan, Interval\n",
    "from gpytorch.kernels import Kernel, MaternKernel, RBFKernel, ScaleKernel\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from gpytorch.priors.torch_priors import GammaPrior, LogNormalPrior\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def get_kernel(dim: int) -> Kernel:\n",
    "    \"\"\"Helper function for kernel construction.\"\"\"\n",
    "    # ard kernel\n",
    "    cont_kernel = MaternKernel(\n",
    "        nu=2.5,\n",
    "        ard_num_dims=dim,\n",
    "        lengthscale_constraint=Interval(0.01, 20.0),\n",
    "    )\n",
    "    return ScaleKernel(cont_kernel)\n",
    "\n",
    "\n",
    "NOISE_SE = 1e-6\n",
    "train_yvar = torch.tensor(NOISE_SE**2, device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "def initialize_model(\n",
    "    train_x, stdized_train_obj, state_dict=None, exact_rounding_func=None\n",
    "):\n",
    "    # define model\n",
    "    model = FixedNoiseGP(\n",
    "        train_x,\n",
    "        stdized_train_obj,\n",
    "        train_yvar.expand_as(stdized_train_obj),\n",
    "        covar_module=get_kernel(dim=train_x.shape[1]),\n",
    "    ).to(train_x)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    # load state dict if it is passed\n",
    "    if state_dict is not None:\n",
    "        model.load_state_dict(state_dict)\n",
    "    return mll, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "e45f8a78-36e4-4692-9ce3-7e883f7780cb",
    "showInput": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Define a helper function that performs the essential BO step\n",
    "The helper function below takes an acquisition function as an argument, optimizes it, and returns the candidate along with the observed function values. \n",
    "\n",
    "`optimize_acqf_cont_relax_and_get_observation` uses a continuous relaxation of the discrete parameters and rounds the resulting candidate.\n",
    "\n",
    "`optimize_acqf_pr_and_get_observation` uses a probabilistic reparameterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "customOutput": null,
    "executionStartTime": 1669843261906,
    "executionStopTime": 1669843261915,
    "originalKey": "3fe3ad5b-dabf-4f13-b95f-0766afdf8920",
    "requestMsgId": "6d1d90c3-d286-4b04-9f70-cf70d175b629",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from botorch.acquisition.probabilistic_reparameterization import (\n",
    "    AnalyticProbabilisticReparameterization,\n",
    "    MCProbabilisticReparameterization,\n",
    ")\n",
    "from botorch.generation.gen import gen_candidates_scipy, gen_candidates_torch\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "NUM_RESTARTS = 20 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 1024 if not SMOKE_TEST else 32\n",
    "\n",
    "\n",
    "def optimize_acqf_cont_relax_and_get_observation(acq_func):\n",
    "    \"\"\"Optimizes the acquisition function, and returns a new candidate and a noisy observation.\"\"\"\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=standard_bounds,\n",
    "        q=1,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "        return_best_only=False,\n",
    "    )\n",
    "    # round the resulting candidates and take the best across restarts\n",
    "    candidates = exact_rounding_func(candidates.detach())\n",
    "    with torch.no_grad():\n",
    "        af_vals = acq_func(candidates)\n",
    "    best_idx = af_vals.argmax()\n",
    "    new_x = candidates[best_idx]\n",
    "    # observe new values\n",
    "    exact_obj = eval_problem(new_x)\n",
    "    return new_x, exact_obj\n",
    "\n",
    "\n",
    "def optimize_acqf_pr_and_get_observation(acq_func, analytic):\n",
    "    \"\"\"Optimizes the acquisition function, and returns a new candidate and a noisy observation.\"\"\"\n",
    "    # construct PR\n",
    "    if analytic:\n",
    "        pr_acq_func = AnalyticProbabilisticReparameterization(\n",
    "            acq_function=acq_func,\n",
    "            one_hot_bounds=one_hot_bounds,\n",
    "            categorical_features=categorical_features,\n",
    "            batch_limit=128,\n",
    "        )\n",
    "    else:\n",
    "        pr_acq_func = MCProbabilisticReparameterization(\n",
    "            acq_function=acq_func,\n",
    "            one_hot_bounds=one_hot_bounds,\n",
    "            categorical_features=categorical_features,\n",
    "            batch_limit=128,\n",
    "            mc_samples=4 if SMOKE_TEST else 128,\n",
    "        )\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=pr_acq_func,\n",
    "        bounds=standard_bounds,\n",
    "        q=1,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "        options={\n",
    "            \"batch_limit\": 5,\n",
    "            \"maxiter\": 200,\n",
    "            \"rel_tol\": float(\"-inf\"),  # run for a full 200 steps\n",
    "        },\n",
    "        # use Adam for Monte Carlo PR\n",
    "        gen_candidates=gen_candidates_torch if not analytic else gen_candidates_scipy,\n",
    "    )\n",
    "    # round the resulting candidates and take the best across restarts\n",
    "    new_x = pr_acq_func.sample_candidates(X=candidates.detach())\n",
    "    # observe new values\n",
    "    exact_obj = eval_problem(new_x)\n",
    "    return new_x, exact_obj\n",
    "\n",
    "\n",
    "def update_random_observations(best_random):\n",
    "    \"\"\"Simulates a random policy by taking a the current list of best values observed randomly,\n",
    "    drawing a new random point, observing its value, and updating the list.\n",
    "    \"\"\"\n",
    "    rand_x = torch.rand(1, one_hot_bounds.shape[1], **tkwargs)\n",
    "    next_random_best = eval_problem(rand_x).max().item()\n",
    "    best_random.append(max(best_random[-1], next_random_best))\n",
    "    return best_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "b9344aeb-149e-46a5-9c17-dfbd9ae4727c",
    "showInput": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Perform Bayesian Optimization loop\n",
    "\n",
    "*Note*: Running this may take a little while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "customOutput": null,
    "executionStartTime": 1669843261955,
    "executionStopTime": 1669843810811,
    "originalKey": "59cbf551-b4a8-4c90-aa4b-b5a3faf7ac54",
    "requestMsgId": "ad801040-9685-4c66-b6c0-4124cddfddf0",
    "showInput": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.acquisition.analytic import ExpectedImprovement\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.utils.transforms import standardize\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "N_TRIALS = 1\n",
    "N_BATCH = 5 if not SMOKE_TEST else 2\n",
    "\n",
    "verbose = True\n",
    "\n",
    "(\n",
    "    best_observed_all_pr,\n",
    "    best_observed_all_pr_analytic,\n",
    "    best_observed_all_cont_relax,\n",
    "    best_random_all,\n",
    ") = ([], [], [], [])\n",
    "\n",
    "\n",
    "# average over multiple trials\n",
    "for trial in range(1, N_TRIALS + 1):\n",
    "\n",
    "    print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
    "    (\n",
    "        best_observed_pr,\n",
    "        best_observed_pr_analytic,\n",
    "        best_observed_cont_relax,\n",
    "        best_random,\n",
    "    ) = ([], [], [], [])\n",
    "\n",
    "    # call helper functions to generate initial training data and initialize model\n",
    "    train_x_pr, train_obj_pr = generate_initial_data(n=20)\n",
    "    best_observed_value_pr = train_obj_pr.max().item()\n",
    "    stdized_train_obj_pr = standardize(train_obj_pr)\n",
    "    mll_pr, model_pr = initialize_model(train_x_pr, stdized_train_obj_pr)\n",
    "\n",
    "    train_x_pr_analytic, train_obj_pr_analytic, stdized_train_obj_pr_analytic = (\n",
    "        train_x_pr,\n",
    "        train_obj_pr,\n",
    "        stdized_train_obj_pr,\n",
    "    )\n",
    "    best_observed_value_pr_analytic = best_observed_value_pr\n",
    "    mll_pr_analytic, model_pr_analytic = initialize_model(\n",
    "        train_x_pr_analytic,\n",
    "        stdized_train_obj_pr_analytic,\n",
    "    )\n",
    "\n",
    "    train_x_cont_relax, train_obj_cont_relax, stdized_train_obj_cont_relax = (\n",
    "        train_x_pr,\n",
    "        train_obj_pr,\n",
    "        stdized_train_obj_pr,\n",
    "    )\n",
    "    best_observed_value_cont_relax = best_observed_value_pr\n",
    "    mll_cont_relax, model_cont_relax = initialize_model(\n",
    "        train_x_cont_relax,\n",
    "        stdized_train_obj_cont_relax,\n",
    "    )\n",
    "\n",
    "    best_observed_pr.append(best_observed_value_pr)\n",
    "    best_observed_pr_analytic.append(best_observed_value_pr_analytic)\n",
    "    best_observed_cont_relax.append(best_observed_value_cont_relax)\n",
    "    best_random.append(best_observed_value_pr)\n",
    "\n",
    "    # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "    for iteration in range(1, N_BATCH + 1):\n",
    "\n",
    "        t0 = time.monotonic()\n",
    "\n",
    "        # fit the models\n",
    "        fit_gpytorch_mll(mll_pr)\n",
    "        fit_gpytorch_mll(mll_pr_analytic)\n",
    "        fit_gpytorch_mll(mll_cont_relax)\n",
    "\n",
    "        # for best_f, we use the best observed values\n",
    "        ei_pr = ExpectedImprovement(\n",
    "            model=model_pr,\n",
    "            best_f=stdized_train_obj_pr.max(),\n",
    "        )\n",
    "\n",
    "        ei_pr_analytic = ExpectedImprovement(\n",
    "            model=model_pr_analytic,\n",
    "            best_f=stdized_train_obj_pr_analytic.max(),\n",
    "        )\n",
    "\n",
    "        ei_cont_relax = ExpectedImprovement(\n",
    "            model=model_cont_relax,\n",
    "            best_f=stdized_train_obj_cont_relax.max(),\n",
    "        )\n",
    "\n",
    "        # optimize and get new observation\n",
    "        new_x_pr, new_obj_pr = optimize_acqf_pr_and_get_observation(\n",
    "            ei_pr, analytic=False\n",
    "        )\n",
    "        new_x_pr_analytic, new_obj_pr_analytic = optimize_acqf_pr_and_get_observation(\n",
    "            ei_pr_analytic, analytic=True\n",
    "        )\n",
    "        (\n",
    "            new_x_cont_relax,\n",
    "            new_obj_cont_relax,\n",
    "        ) = optimize_acqf_cont_relax_and_get_observation(ei_cont_relax)\n",
    "        \n",
    "        print(f\"MC: {new_x_pr}\")\n",
    "        print(f\"analytic: {new_x_pr_analytic}\")\n",
    "        # update training points\n",
    "        train_x_pr = torch.cat([train_x_pr, new_x_pr])\n",
    "        train_obj_pr = torch.cat([train_obj_pr, new_obj_pr])\n",
    "        stdized_train_obj_pr = standardize(train_obj_pr)\n",
    "\n",
    "        train_x_pr_analytic = torch.cat([train_x_pr_analytic, new_x_pr_analytic])\n",
    "        train_obj_pr_analytic = torch.cat([train_obj_pr_analytic, new_obj_pr_analytic])\n",
    "        stdized_train_obj_pr_analytic = standardize(train_obj_pr_analytic)\n",
    "\n",
    "        train_x_cont_relax = torch.cat([train_x_cont_relax, new_x_cont_relax])\n",
    "        train_obj_cont_relax = torch.cat([train_obj_cont_relax, new_obj_cont_relax])\n",
    "        stdized_train_obj_cont_relax = standardize(train_obj_cont_relax)\n",
    "\n",
    "        # update progress\n",
    "        best_random = update_random_observations(best_random)\n",
    "        best_value_pr_analytic = train_obj_pr.max().item()\n",
    "        best_value_pr = train_obj_pr_analytic.max().item()\n",
    "        best_value_cont_relax = train_obj_cont_relax.max().item()\n",
    "        best_observed_pr.append(best_value_pr)\n",
    "        best_observed_pr_analytic.append(best_value_pr_analytic)\n",
    "        best_observed_cont_relax.append(best_value_cont_relax)\n",
    "\n",
    "        # reinitialize the models so they are ready for fitting on next iteration\n",
    "        # use the current state dict to speed up fitting\n",
    "        mll_pr, model_pr = initialize_model(\n",
    "            train_x_pr,\n",
    "            stdized_train_obj_pr,\n",
    "        )\n",
    "        mll_pr_analytic, model_pr_analytic = initialize_model(\n",
    "            train_x_pr_analytic,\n",
    "            stdized_train_obj_pr_analytic,\n",
    "        )\n",
    "        mll_cont_relax, model_cont_relax = initialize_model(\n",
    "            train_x_cont_relax,\n",
    "            stdized_train_obj_cont_relax,\n",
    "        )\n",
    "\n",
    "        t1 = time.monotonic()\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"\\nBatch {iteration:>2}: best_value (random, Cont. Relax., PR (MC), PR (Analytic)) = \"\n",
    "                f\"({max(best_random):>4.2f}, {best_value_cont_relax:>4.2f}, {best_value_pr:>4.2f}, {best_value_pr_analytic:>4.2f}), \"\n",
    "                f\"time = {t1-t0:>4.2f}.\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        else:\n",
    "            print(\".\", end=\"\")\n",
    "\n",
    "    best_observed_all_pr.append(best_observed_pr)\n",
    "    best_observed_all_pr_analytic.append(best_observed_pr_analytic)\n",
    "    best_observed_all_cont_relax.append(best_observed_cont_relax)\n",
    "    best_random_all.append(best_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "originalKey": "587be90e-69f5-4b33-ad40-1aafe38d305c",
    "showInput": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot the results\n",
    "The plot below shows the best objective value observed at each step of the optimization for each of the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "customOutput": null,
    "executionStartTime": 1669843815143,
    "executionStopTime": 1669843815915,
    "originalKey": "cd365490-cf84-4456-a033-3b58879a0293",
    "requestMsgId": "03a1289e-6f40-4066-aced-875fb75dac36",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def ci(y):\n",
    "    return 1.96 * y.std(axis=0) / np.sqrt(N_TRIALS)\n",
    "\n",
    "\n",
    "iters = np.arange(N_BATCH + 1)\n",
    "y_cont_relax = np.asarray(best_observed_all_cont_relax)\n",
    "y_pr = np.asarray(best_observed_all_pr)\n",
    "y_pr_analytic = np.asarray(best_observed_all_pr_analytic)\n",
    "y_rnd = np.asarray(best_random_all)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "ax.errorbar(iters, y_rnd.mean(axis=0), yerr=ci(y_rnd), label=\"Random\", linewidth=1.5)\n",
    "ax.errorbar(\n",
    "    iters,\n",
    "    y_cont_relax.mean(axis=0),\n",
    "    yerr=ci(y_cont_relax),\n",
    "    label=\"Cont. Relax.\",\n",
    "    linewidth=1.5,\n",
    ")\n",
    "ax.errorbar(iters, y_pr.mean(axis=0), yerr=ci(y_pr), label=\"PR (MC)\", linewidth=1.5)\n",
    "ax.errorbar(iters, y_pr_analytic.mean(axis=0), yerr=ci(y_pr_analytic), label=\"PR (Analytic)\", linewidth=1.5)\n",
    "ax.set(\n",
    "    xlabel=\"number of observations (beyond initial points)\",\n",
    "    ylabel=\"best objective value\",\n",
    ")\n",
    "ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "customInput": null,
    "originalKey": "e9baed40-d083-47fb-aa14-03addfd33948",
    "showInput": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dataExplorerConfig": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "last_base_url": "https://10809.od.fbinfra.net:443/",
  "last_kernel_id": "28f4e6d7-8588-4a44-a9cd-72f1c86fe424",
  "last_msg_id": "4fc1bf58-e85662233f122503abcfda0d_71",
  "last_server_session_id": "96862577-2347-40d6-a7f0-e7fda4e0662d",
  "outputWidgetContext": {}
 },
 "nbformat": 4,
 "nbformat_minor": 2
}